---
status: ACTIVE
type: Plan
---

> **Context:**
> *   [2026-01-15 17:15 UTC]: Recovery Manifest created following VS Code session crash and vLLM engine failure.
> *   **Purpose:** Re-establish context, link fragmented logs, and define the immediate path forward.
> **Parent Documents:**
>    - [20260115-C-NEW-001.1-Component-Analysis-Report.md](./20260115-C-NEW-001.1-Component-Analysis-Report.md) (Contains the latest Incident Log in Appendix)
>    - [20260115-C-NEW-001.2-Final-Investigation-Summary.md](./20260115-C-NEW-001.2-Final-Investigation-Summary.md) (Summary of the Logic Bug Fix)

---

# C-NEW-001.3: Recovery Manifest & Incident Index

## 1. The Narrative So Far (Reconstruction)

The "Humpty Dumpty" view of the last 4 hours:

1.  **The Trigger (15:00 UTC):** [Component Analysis (.1)](./20260115-C-NEW-001.1-Component-Analysis-Report.md) revealed that Mistral Logic scores (0.870) inexplicably beat Qwen (0.666).
2.  **The Investigation (15:30-16:30 UTC):**
    - [Debug Session (.2)](./20260115-C-NEW-001.2-Debug-Session.md) launched.
    - [Critical Bug Found (.2a)](./20260115-C-NEW-001.2a-CRITICAL-BUG-Logic-Timeouts.md): Logic Judge was timing out at 85s on Qwen's code.
    - **Fix Applied:** Timeout increased to 200s.
3.  **The Resolution Attempt (16:30 UTC):**
    - [Investigation Summary (.2)](./20260115-C-NEW-001.2-Final-Investigation-Summary.md) declared the bug fixed.
    - **Action:** Tier 2 (Qwen) Rerun initiated to validate the fix.
4.  **The Crash (16:55 UTC):**
    - During the rerun, `vLLM` failed with `nanobind reference counting issue`.
    - VS Code session context was lost.
    - **Current Log:** The failure details are appended to the [Component Analysis Report (.1)](./20260115-C-NEW-001.1-Component-Analysis-Report.md#2026-01-15-investigation-plan-log-tier-2-rerun--vllm-engine-failure).

---

## 2. Current State Assessment

- **Investigation Status:** âœ… RESUMED
- **Infrastructure Status:** ðŸŸ¢ RESTORED (vLLM Restarted on Port 8001)
- **Logic Bug Status:** âœ… VERIFIED (Validation run showed scores ~0.80)
- **Active Task:** Full Tier 2 Rerun (25 battles) in progress.

---

## 3. Immediate Action Plan

**Objective:** execute the plan defined in the [.1 Appendix](./20260115-C-NEW-001.1-Component-Analysis-Report.md#2026-01-15-investigation-plan-log-tier-2-rerun--vllm-engine-failure) to restore vLLM and complete the rerun.

### Step 1: Technical Rescue (Priority) - âœ… COMPLETE
1.  **Clean Process Kill:** Ensure no zombie vLLM processes.
2.  **Resource Check:** Verify GPU memory is free.
3.  **Restart vLLM:** Attempt clean launch of Qwen-32B.
4.  **Verification:** Simple curl test to confirm model is serving.

### Step 2: Resume Validation - âœ… COMPLETE
1.  **Rerun Tier 2:** Execute `run_tier2_qwen.py` (2 battles).
    - **Result:** Success (0.81, 0.75 scores). Logic timeout fixed.
2.  **Full Rerun:** Execute `run_tier2_qwen.py` (25 battles).
    - **Status:** Started in background.

### Step 3: Documentation Cleanup (Post-Fix)
*Once system is stable:*
1.  Consolidate the "Appendix" from .1 into a proper `20260115-C-NEW-001.3-Infrastructure-Incident.md`.
2.  Update [20260115-Session-Summary.md](./20260115-Session-Summary.md) to reflect the crash and recovery.

---

## 4. Work Log (Recovery Phase)

**17:30 UTC: vLLM & Agent Rescue**
- **Action:** Killed stuck vLLM processes.
- **Investigation:** Discovered `purple-agent` and `green-agent` were misconfigured (looking for `mistral` model, not `Qwen`).
- **Fix:**
  - Restarted vLLM on port 8001.
  - Recreated `purple-agent` container with `OPENAI_MODEL=Qwen/Qwen2.5-Coder-32B-Instruct-AWQ` and `OPENAI_BASE_URL=http://localhost:8001/v1`.
  - Recreated `green-agent` container with `MODEL_NAME=Qwen/Qwen2.5-Coder-32B-Instruct-AWQ` and `OPENAI_BASE_URL=http://localhost:8001/v1`.
  - Re-patched `src/green_logic/scoring.py` in Green Agent (timeout=200s).

**17:50 UTC: Validation Success**
- **Outcome:** Rerun of 2 battles produced scores of 0.81 and 0.75.
- **Meaning:**
  - Connectivity restored.
  - Logic Judge is successfully reviewing code (no 0.5 penalties).
  - Logic Bug (timeouts) confirmed fixed.

**19:15 UTC: Progress Update**
- **Status:** 12/25 battles complete.
- **Recent Scores:** 0.74, 0.72, 0.55, 0.50.
- **Health:** Stable.
- **ETA:** ~19:55 UTC (Slowed slightly).
- **Note:** User inquiry regarding Tier 1/3 rerun. Recommendation: Rerun for scientific rigor, though strictly speaking the logic bug didn't affect them.

**19:30 UTC: Technical Clarification**
- **Topic:** "Timeout" vs "Streaming" Confusion.
- **Assessment:** Validated that `scoring.py` *was* correctly using `stream=True` for Logic Reviews all along.
- **Root Cause:** The "Timeout" errors were not due to a lack of streaming implementation, but rather **Infrastructure Latency**. The vLLM backend (on the previous shared port) was stalling/overloaded, causing the stream generator to hang longer than the client's patience threshold.
- **Resolution:** Moving to a dedicated port (8001) + increasing the client timeout (200s) provided the necessary buffer for the stream to complete successfully under load.

