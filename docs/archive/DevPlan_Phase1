(This dev plan has been completed as of 06.01.2025, but many errors have arised in the lint logs.)

Here is the rewritten Phase 1 Development Plan, version 3.0, incorporating all the architectural decisions for the Cognitive Context Engine (CCE) and Vector Translation Core (VTC), and aligning with your improved workflow for AI agent development.
This updated plan includes provisions for the plugin contract layer, runtime logic/command bus, and input/output interfaces, specifically focusing on stubbing out the necessary interfaces and modifying Phase 1 tasks to ensure future compatibility, as discussed.
PHASE 1: Backend Implementation, Data Persistence, and Core AI Foundation Scaffolding (v3.0)
Estimated Duration: 3-4 Weeks
Prerequisite: Successful completion of all Phase 0: Framework-First Architecture Setup & Core Logic Decoupling tasks. This implies the following project state:
 * A React application in src/ that has been decoupled from direct data management.
 * An in-memory IdeaManager managing thought data for the session after an initial load from localStorage.
 * TypeScript data contracts (DTOs) for Thought, Segment, Tag, LLMExecutor, etc., defined in contracts/.
 * Core utilities for ID generation (core/utils/idUtils.ts) and logging (core/utils/logger.ts, core/logger/llmAuditLogger.ts).
 * Basic unit test stubs for IdeaManager in core/.
 * Path aliases (@core, @contracts) configured in tsconfig.json (or jsconfig.json) with baseUrl: "." and paths for src, core, and contracts.
 * Placeholder documentation for DevOps, UX, and data migration.
Goal:
This phase transitions LogoMesh from an application reliant on in-memory data (post-initial load) to a robust, local-first application with persistent data storage using SQLite. It involves building a lightweight backend API server (Node.js/Express.js), integrating SQLite into the core data management layer (IdeaManager) via a StorageAdapter pattern, and connecting the React frontend to this new backend. Crucially, this phase also lays fundamental architectural groundwork for the Vector Translation Core (VTC) and the Cognitive Context Engine (CCE), ensuring future AI capabilities can be seamlessly integrated. This includes refining the graph visualization, laying the groundwork for local automation with Node-RED, and implementing the initial (mocked/stubbed) LLM execution layer. All development must adhere to environment-aware configurations for flexible deployment (local development and Replit).
Key Outcomes for Phase 1:
 * A functional backend API server (Node.js/Express.js) serving data from an SQLite database, configurable via environment variables.
 * The IdeaManager refactored to use a persistent SQLite data store through a StorageAdapter pattern.
 * The React application (src/) fully communicates with the backend API for all core data operations.
 * An initial, simple implementation of the LLMExecutor interface (e.g., for Ollama as a mock) and LLMTaskRunner integrated into the backend, designed to support future VTC and optional external LLMs via API keys.
 * Node-RED instance set up with foundational API integrations to the backend for basic automation workflows.
 * Cytoscape.js graph visualization in the React app refined for compound nodes and fcose layout.
 * JSON import/export functionality available via the backend API.
 * The backend API and SQLite database containerized using Docker for consistent local development.
 * A defined process and script for migrating initial data from localStorage to the new SQLite database.
 * Sample Replit configuration files (.replit, replit.nix) for demo deployment.
 * Foundational interfaces and architectural provisions for the Vector Translation Core (VTC) are stubbed within contracts/embeddings/ and core/embeddings/, ensuring all embedding interactions are abstracted and ephemeral.
 * Foundational interfaces and conceptual plans for the Cognitive Context Engine (CCE) are planned within core/services/ (or core/context/), with the ThoughtExportProvider being enhanced to support semantic compression for its future needs.
Tier #1: Local-First Full Immersion
Tasks:
1. Project & Environment Setup for Phase 1 Backend Development:
* Framework Outcome: Core services and the new server can be configured via environment variables. Project structure is prepared for backend development and Replit deployment.
* Detailed Actions (for AI Agent):
a.  Establish .env Configuration:
* Create an .env.example file in the project root directory.
* Populate it with placeholder environment variables for:
* PORT (e.g., 3001)
* API_BASE_PATH (e.g., /api/v1)
* DB_PATH (e.g., ./data/logomesh.sqlite3 - this path will be relative to where the server runs, likely server/data/logomesh.sqlite3 or a Replit persistent path).
* PLUGIN_DIR (e.g., ./plugins - relative to server/core).
* LOG_LEVEL (e.g., info).
* DEFAULT_LLM_EXECUTOR (e.g., MockLLMExecutor).
* ULS_DIMENSION (e.g., 768) - New for VTC scaffolding.
* REACT_APP_API_URL (e.g., http://localhost:3001/api/v1) - For frontend configuration.
* Add .env to the .gitignore file.
* (Note for AI Agent): Subsequent tasks will require reading these variables using process.env.VARIABLE_NAME || 'defaultValue'.
b.  Create Replit Configuration Files (for replit-demo branch):
* Generate a sample .replit file in the project root.
* The run command should correctly start the backend API server (e.g., cd server && npm run start or pnpm --filter ./server start).
* It should respect environment variables provided by Replit (like $PORT).
* Generate a sample replit.nix file in the project root.
* Include pkgs.nodejs (e.g., v18 or v20) and pkgs.sqlite (system library for the sqlite3 Node.js module).
* Define any necessary environment variables if Replit doesn't set them automatically (e.g., DB_PATH pointing to Replit's persistent storage like /mnt/data/logomesh.sqlite3).
* Verification: Project can be configured to run on Replit.
2. Backend API Server & SQLite Database Foundation:
* Framework Outcome: A runnable Node.js/Express.js backend server and an initialized SQLite database with the correct schema.
* Detailed Actions (for AI Agent):
a.  Set Up Backend Server Project (server/ directory):
* Create a new top-level directory named server/.
* Initialize a Node.js project within server/ (npm init -y or equivalent).
* Install dependencies: express, cors, sqlite3.
* Set up for TypeScript: install typescript, @types/express, @types/cors, @types/node, ts-node, nodemon as dev dependencies. Create server/tsconfig.json (module: commonjs, target: es2020, outDir: ./dist, rootDir: ./src, esModuleInterop: true, resolveJsonModule: true). Create server/src/ for source files. Add build/start/dev scripts to server/package.json.
* Create server/src/index.ts as the main server entry point.
* Implement Express app setup: use cors(), express.json().
* Add a GET /api/v1/health route (use process.env.API_BASE_PATH) returning { status: "healthy", timestamp: new Date().toISOString() }.
* Start server on process.env.PORT || 3001.
* Implement Bootstrap Logging: At startup, log (using @core/utils/logger.ts via relative path or updated alias) the perceived environment, port, DB_PATH (from process.env), and PLUGIN_DIR.
* Verification: Express server starts, health check works, bootstrap logs appear.
b.  Define and Initialize SQLite Database Schema:
* (Prerequisite Check): Ensure the "Phase 1 SQLite Schema" section in docs/Merged Milestone-Based Development Plan v2.0.md is complete and accurate, detailing all tables, columns, types, keys, and constraints for thoughts, segments, tags, thought_tags, segment_tags, segment_fields, segment_neighbors, segment_related_context, segment_llm_history.
* In core/db/schema.sql (created in Phase 0), populate with CREATE TABLE statements from the verified plan.
* In core/db/initDb.ts (created in Phase 0), implement initializeDatabase():
* Use sqlite3. Connect to process.env.DB_PATH (defaulting to server/data/logomesh.sqlite3 if run from server dir, or core/db/logomesh.sqlite3 if run from core dir â€“ path needs to be robust). Create the data directory if it doesn't exist.
* Read core/db/schema.sql. Execute CREATE TABLE IF NOT EXISTS ... for all tables.
* Use logger from core/utils/logger.ts.
* Modify server/src/index.ts startup sequence to call await initializeDatabase() before starting the Express listener, ensuring the DB is ready. Handle potential errors during DB initialization.
* Verification: Server startup initializes the DB. logomesh.sqlite3 is created at the configured DB_PATH with the correct schema.
c.  Integrate LLM Execution Layer Stubs:
* Create core/llm/OllamaExecutor.ts implementing LLMExecutor from contracts/llmExecutor.ts. executePrompt returns a mocked response (e.g., Promise.resolve(\Mocked response for: ${prompt}`)). supportsStreamingisfalse. * Create core/llm/LLMTaskRunner.tsclass withconstructor(private executor: LLMExecutor)andasync run(prompt: string, metadata?: Record<string, any>): Promise<string>method that callsthis.executor.executePromptand logs vialogLLMInteractionfromcore/logger/llmAuditLogger.ts. Include the runPromptWithStreaming?stub. * Createcore/llm/utils/mermaidAuditor.tswith stubisValidMermaidfunction. * Createserver/src/routes/llmRoutes.ts: POST /api/v1/llm/promptendpoint usingLLMTaskRunnerwith an instance ofMockLLMExecutor(fromcore/llm/MockLLMExecutor.tscreated in Phase 0) or the newOllamaExecutorstub. Mount this router inserver/src/index.ts. * **Crucial VTC Preparation:** Ensure LLMExecutorimplementations (includingMockLLMExecutorandOllamaExecutor.tsstub) **do not hardcode assumptions about embedding formats or types**. They should be designed to receive context/prompts that *could* originate from a VTC-translated source in future phases. * *Verification:*POSTto/api/v1/llm/promptreturns mock response and logs viallmAuditLogger`.
d.  Define VTC & Embedding Interfaces (Crucial for Phase 2 readiness):
* Purpose: To establish the foundational TypeScript interfaces for the Vector Translation Core (VTC), ensuring that all embedding interactions within LogoMesh are abstracted and that the system is ready for multi-model and multi-modal embedding translation in Phase 2. This also includes defining an "Ephemeral Embedding Policy" to avoid persistent storage of raw embeddings.
* Create new directory: contracts/embeddings/.
* Create contracts/embeddings/embeddingInterface.ts.
typescript // contracts/embeddings/embeddingInterface.ts /** * Abstract interface for all embedding interactions to ensure model-agnostic handling. * Components interacting with embeddings (e.g., ShellNode, EchoMesh) should use this. */ export interface EmbeddingInterface { toVector(input: any): Promise<number[]>; fromVector(vector: number[]): Promise<any>; getModelName(): string; getDimension(): number; } 
* Create contracts/embeddings/ulsConfig.ts.
typescript // contracts/embeddings/ulsConfig.ts /** * Defines configuration for the Universal Latent Space (ULS) for VTC. * Its parameters (e.g., dimension) will be crucial for VTC training/inference. */ export interface ULSConfig { dimension: number; // E.g., 512, 768, 1024 (from ULS_DIMENSION env var) // Add other ULS specific configs as needed for VTC training/inference } 
* Create contracts/embeddings/adapterRegistry.ts.
```typescript
// contracts/embeddings/adapterRegistry.ts
import { EmbeddingInterface } from './embeddingInterface';
/**
* Interface for registering and retrieving different embedding adapters for VTC.
* This allows dynamic loading of model-specific input/output adapters.
*/
export interface AdapterRegistry {
registerAdapter(modelName: string, inputAdapter: EmbeddingInterface, outputAdapter: EmbeddingInterface): void;
getInputAdapter(modelName: string): EmbeddingInterface | undefined;
getOutputAdapter(modelName: string): EmbeddingInterface | undefined;
}
```
* Ephemeral Embedding Policy Enforcement:
* Review any existing (or soon-to-be implemented) code paths in src/ or core/ that might handle or store raw embedding vectors (e.g., in Thought or Segment DTOs, or temporary memory).
* Ensure that any raw embedding vectors are treated as ephemeral and not persistently stored in the database or localStorage. If they must be stored temporarily, implement a TTL (time-to-live) mechanism or clear them after use. This prepares for the VTC's secure latent vector substitution in Phase 2.
* (Note for AI Agent: For Segment's embedding_vector? field, it should be understood as a conceptual placeholder for future processed/translated embeddings or for use with a dedicated local embedding service that runs after VTC has potentially translated them.)
* Verification: New files are created in contracts/embeddings/ with the specified interfaces. Code practices avoid persistent raw embedding storage.
3. Implement Persistent Data Management (StorageAdapter & IdeaManager Refactor):
* Framework Outcome: IdeaManager uses SQLite for persistence via the StorageAdapter pattern.
* Detailed Actions (for AI Agent):
a.  Define StorageAdapter Interface (contracts/storageAdapter.ts - created in Phase 0):
* Ensure this interface includes async CRUD methods for Thought, Segment (e.g., getAllThoughts, createThought, getSegmentsForThought, createSegment, etc.) returning Promises. Define NewThoughtData, NewSegmentData input types.
* Verification: Interface is complete and matches ARCHITECTURE.MD v2.8.
b.  Implement SQLiteStorageAdapter (core/storage/sqliteAdapter.ts - created in Phase 0):
* Implement the SQLiteStorageAdapter class satisfying the StorageAdapter interface.
* Constructor takes dbPath: string (from process.env.DB_PATH).
* Uses sqlite3 for all SQL operations. Implement all CRUD methods, mapping DTOs to/from the normalized SQLite schema (including handling segment_fields, thought_tags, segment_tags internally for createThought, updateSegment, etc.). Use parameterized queries. Use core/utils/logger.ts.
* (Note for AI Agent): Implement method-by-method. This is a complex task. Prioritize robust DTO <-> DB mapping and error handling.)
* Verification: (Verified by unit tests in Task 10c).
c.  Refactor IdeaManager (core/IdeaManager.ts):
* Modify constructor: constructor(private storage: StorageAdapter, /* other services like logger */) {}.
* Remove in-memory this.thoughts array and localStorage loading logic from constructor.
* Rewrite all public CRUD methods to be async and delegate to this.storage.method(...). ID generation (from core/utils/idUtils.ts) remains in IdeaManager before calling adapter's create methods.
* Verification: IdeaManager methods are async and correctly use the storage adapter.
4. Implement Backend API Endpoints for Core Entities:
* Framework Outcome: Backend API exposes RESTful CRUD for Thoughts and Segments.
* Detailed Actions (for AI Agent):
a.  Instantiate Core Services in Server (server/src/index.ts):
* Create instances: const sqliteAdapter = new SQLiteStorageAdapter(process.env.DB_PATH || './data/logomesh.sqlite3');
* const ideaManager = new IdeaManager(sqliteAdapter, logger);
* Make ideaManager (and other core services like LLMTaskRunner, PortabilityService once created) available to route handlers (e.g., via Express app locals, or by passing them when setting up routes).
* Verification: Server instantiates services with SQLiteStorageAdapter.
b.  Create API Routes for Thoughts (server/src/routes/thoughtRoutes.ts):
* Implement Express router for /api/v1/thoughts.
* Endpoints: GET /, POST /, GET /:thoughtId, PUT /:thoughtId, DELETE /:thoughtId.
* Handlers call respective ideaManager methods. Implement request body validation, error handling (returning appropriate HTTP statuses), and logging.
* Mount in server/src/index.ts.
* Verification: Endpoints function correctly; data persists in SQLite.
c.  Create API Routes for Segments (e.g., nested under thoughts):
* In thoughtRoutes.ts or new segmentRoutes.ts, implement:
* POST /api/v1/thoughts/:thoughtId/segments
* PUT /api/v1/thoughts/:thoughtId/segments/:segmentId
* DELETE /api/v1/thoughts/:thoughtId/segments/:segmentId
* Similar logic, validation, error handling.
* Verification: Segment CRUD via API works.
5. Refactor React Frontend to Consume Backend API:
* Demo Implementation Outcome: React app uses HTTP requests for all data operations.
* Detailed Actions (for AI Agent):
a.  Create API Service Layer (src/services/apiService.ts):
* Module to encapsulate Workspace/axios calls to process.env.REACT_APP_API_URL || 'http://localhost:3001/api/v1'.
* Export async functions for all CRUD operations (e.g., WorkspaceThoughts(), createThoughtApi(data: NewThoughtData)). Basic error handling (check response.ok).
* Verification: apiService.ts created with necessary functions.
b.  Refactor src/App.jsx:
* Remove IdeaManager direct usage. Import and use apiService.
* useEffect on mount calls apiService.fetchThoughts().
* createThought calls apiService.createThoughtApi(), then re-fetches all thoughts (initial strategy).
* refreshThoughts callback (for children) calls apiService.fetchThoughts().
* Verification: App.jsx loads and modifies data via API.
c.  Refactor Child Components (e.g., ThoughtDetailPanel.jsx, Canvas.jsx):
* Remove ideaManager prop. Use callbacks from App.jsx that invoke apiService methods, followed by refreshThoughts.
* Verification: UI interactions for data modification use the API. Data persists across reloads.
6. Refine Graph Visualization (Cytoscape.js):
* Demo Implementation Outcome: Graph canvas visualizes Thoughts as compound parents with Segment children, using fcose layout.
* Detailed Actions (for AI Agent):
a.  Modify src/components/Canvas.jsx for Compound Nodes:
* Refactor elements generation: Segment nodes' data object must include parent: thought.thought_bubble_id.
* Remove direct Thought-to-Segment edges; prioritize compound representation.
* Verification: Segments appear nested in thought bubbles.
b.  Integrate and Configure cytoscape-fcose Layout:
* Ensure cytoscape.use(fcose); is called. Set layout: { name: 'fcose', ... }.
* Configure fcose parameters for clarity (refer to ARCHITECTURE.MD v2.8 for goals).
* Verification: Graph uses fcose; compound nodes are clearly arranged.
c.  Handle Node Position Updates:
* dragfree event saves positions of compound Thought nodes via apiService.updateThoughtApi(...).
* Verification: Dragging thoughts updates position via API.
7. Scaffold Cognitive Context Engine (CCE) Foundations:
* Framework Outcome: Initial interfaces and conceptual plans for the CCE are in place, with the ThoughtExportProvider being enhanced for semantic compression.
* Detailed Actions (for AI Agent):
a.  Create CCE Placeholder Module:
* Create directory core/context/.
* Create core/context/cognitiveContextEngine.ts as a planned stub. Its purpose will be to act as the "semantic lens" for context generation in future phases.
* ```typescript
// core/context/cognitiveContextEngine.ts
/**
* @module CognitiveContextEngine
* @description Planned for Phase 2+. Responsible for dynamically assembling and refining contextually relevant information from the knowledge graph.
* Acts as a semantic lens and compression engine for LLM interactions.
* (Stub for Phase 1)
/
export class CognitiveContextEngine {
constructor(/ Dependencies like IdeaManager, MeshGraphEngine, VTC */) {
// Logic planned for Phase 2+
}
// Planned method stubs for context generation:
async generateContextForLLM(thoughtId: string, query: string, options?: any): Promise<any> {
// This method will leverage ThoughtExportProvider and potentially VTC
console.log([CCE Stub] Generating context for thought ${thoughtId} with query: ${query});
return Promise.resolve("Mock context based on thought title.");
}
// Other planned methods: getRelatedContext, compressContext, etc.
}
```
* (Note for AI Agent): For Phase 1, the CCE itself is a conceptual placeholder. The focus is on its foundational dependencies.)
b.  Enhance ThoughtExportProvider (contracts/thoughtExportProvider.ts and core/services/portabilityService.ts):
* Review and ensure the ThoughtExportProvider interface in contracts/thoughtExportProvider.ts (or equivalent interface within IdeaManager or PortabilityService if not a standalone interface yet) can support options related to semantic compression, such as abstractionLevelFilter, localPriorityThreshold, clusterIdFilter, maxDepth (simulated).
* Within core/services/portabilityService.ts (or wherever exportData lives), ensure the exportData method's implementation can conceptually filter and organize data based on these semantic compression options, even if the actual "compression" logic is rudimentary in Phase 1 (e.g., just basic filtering before full semantic summarization).
* The MeshGraphEngine (core/services/meshGraphEngine.ts) should also have its stubbed methods (e.g., getRelatedThoughts, clusterThoughtsByTag) enhanced to support these semantic filtering/traversal concepts, which the CCE will rely on later.
* Verification: CognitiveContextEngine.ts stub exists. ThoughtExportProvider interface and initial implementation (in PortabilityService or IdeaManager) can accept and rudimentary apply semantic compression options. MeshGraphEngine stubs conceptually support semantic traversal for CCE.
8. Set Up Node-RED & Initial Integration:
* Framework Outcome: Node-RED configured to interact with backend API.
* Detailed Actions (Developer/AI Agent):
a.  Install and Configure Node-RED Locally:
* Standard install. Add node-red-node-http.
* Verification: Node-RED runs.
b.  Implement Backend Backup API Endpoint (server/src/routes/adminRoutes.ts):
* Create POST /api/v1/admin/backup. Uses Node.js fs to copy the DB file (from process.env.DB_PATH) to a timestamped backup in server/backups/ (ensure this directory path is also configurable or relative to a known location).
* Mount router in server/src/index.ts.
* Verification: API endpoint creates a DB backup file.
c.  Scaffold Node-RED Workflows:
* Backup Workflow: Timer -> HTTP POST to /api/v1/admin/backup.
* Auto-Tagging Prep Stub: Timer -> HTTP GET /api/v1/thoughts -> Function node (basic keyword logic) -> (Conceptual) HTTP PUT to update segment tags.
* Embedding Prep Stub: Timer -> HTTP GET segments -> HTTP POST to /api/v1/llm/prompt with segment content. This will leverage the LLM execution layer stubs.
* Verification: Flows trigger, make API calls, backup workflow creates file, embedding prep logs via llmAuditLogger.
9. Implement JSON Import/Export via Backend API:
* Framework Outcome: Core import/export logic in core/services/portabilityService.ts exposed via API.
* Detailed Actions (for AI Agent):
a.  Create core/services/portabilityService.ts:
* Constructor takes StorageAdapter.
* exportData(): Promise<ThoughtWebExport>: Fetches all data via adapter, assembles into standard JSON.
* importData(jsonData: ThoughtWebExport): Promise<void>: Parses, validates, uses adapter to insert/update data.
* Verification: Unit tests for PortabilityService (Task 10c).
b.  Create API Endpoints (server/src/routes/portabilityRoutes.ts):
* GET /api/v1/export/json: Calls portabilityService.exportData(), streams JSON file.
* POST /api/v1/import/json: Accepts JSON file upload (use multer for Express), passes to portabilityService.importData().
* Mount router.
* Verification: Endpoints function correctly.
c.  Update React UI (src/components/Sidebar.jsx):
* Refactor handleExportAll (GET to export endpoint) and handleImport (POST file to import endpoint). Remove old client-side utils.
* Verification: UI import/export uses backend API.
10. DevOps & UX Foundations (Continued):
* Framework Outcome: Backend containerized. Basic UI/UX docs reviewed. Test coverage improved.
* Detailed Actions (for AI Agent/Developer):
a.  Containerize Backend API & SQLite (Dockerfile, docker-compose.yml):
* Dockerfile for server/ (Node.js, copy core/, contracts/, install server deps, build TS, expose port, run server).
* docker-compose.yml: logomesh-api service using Dockerfile. Map ports. Pass environment variables (DB_PATH, PORT). Mount volumes for SQLite DB (./data -> container's DB_PATH) and backups (./backups -> container's backup path).
* Ensure Docker startup runs initializeDatabase() if DB volume is empty.
* (Note for AI Agent): React dev server and Node-RED Dockerization is optional for Phase 1, focus on API+DB container.)
* Verification: docker-compose up starts API. Data persists.
b.  Data Migration Script Implementation (from localStorage to SQLite):
* (This task executes the placeholder from Task 2c of original plan).
* Create a script (e.g., core/scripts/migrateLegacyData.ts) that:
* Reads data from localStorage key 'thought-web-data'.
* Parses it (handling old array format and new object format).
* Connects to the SQLite database (using SQLiteStorageAdapter's methods or direct sqlite3 calls with the same logic).
* Transforms and inserts the legacy thoughts, segments, tags, and fields into the new normalized SQLite tables. Handle potential conflicts (e.g., skip if ID exists).
* Add a script to package.json to run this migration.
* Update /docs/DATA_MIGRATION.md with instructions on when/how to run this script.
* Verification: Script successfully migrates data from a sample localStorage export into SQLite.
c.  Update and Expand Unit/Integration Tests:
* Backend API Tests (server/src/routes/tests/): Use supertest + Jest for API endpoints.
* SQLiteStorageAdapter Tests (core/storage/sqliteAdapter.test.ts): Unit test each method.
* IdeaManager Tests (core/IdeaManager.test.ts): Use mock StorageAdapter.
* PortabilityService Tests (core/services/portabilityService.test.ts): Test import/export.
* VTC Interface Tests (core/embeddings/vectorTranslationCore.test.ts): Add basic tests to confirm VTC interfaces are correctly stubbed and placeholder methods behave as expected.
* Verification: Test coverage increased. Tests pass.
d.  UX Foundations - Docs & UI Review:
* Review /docs/STYLE_GUIDE.md, /docs/ONBOARDING_TOUR.md.
* Ensure basic UI interactions are functional post-refactor.
* Verification: Docs reviewed. UI functional.
11. Scaffold Plugin Runtime Interface & Manifest Extension:
* Framework Outcome: A formal plugin runtime contract is defined, and the plugin manifest supports dynamic translator attachments and basic context-aware loading.
* Detailed Actions (for AI Agent):
a.  Create Plugin Runtime Interface:
* Create new directory: core/plugins/.
* Create core/plugins/pluginRuntimeInterface.ts.
```typescript
// core/plugins/pluginRuntimeInterface.ts
import { EventBus } from '../services/eventBus';
import { PluginAPI } from '../contracts/plugins/pluginApi';
import { CognitiveContextEngine } from '../context/cognitiveContextEngine'; // Future dependency
/**
* Defines the core runtime lifecycle methods for LogoMesh plugins.
* This contract allows dynamic logic engines and simulation modules to be docked.
*/
export interface PluginRuntimeInterface {
name: string;
version: string;
dependencies?: string[]; // Other plugin names or core service versions
/**
* Called once when the plugin is loaded. Used for setup and initializations.
* @param pluginApi - The API provided by the PluginHost to interact with LM-Core services.
* @param eventBus - The global EventBus for sending/receiving signals.
* @param config - Plugin-specific configuration.
*/
init(pluginApi: PluginAPI, eventBus: EventBus, config?: Record<string, any>): Promise<void>;
/**
* Called when the plugin is enabled and its state should be loaded or initialized.
* @param initialState - Any state to be passed to the plugin upon activation.
*/
onLoad?(initialState?: any): Promise<void>;
/**
* Called periodically for continuous logic or simulation updates (e.g., per frame in a game engine).
* @param delta - Time elapsed since the last update.
*/
onUpdate?(delta: number): Promise<void>;
/**
* Called when a specific command is issued to the plugin.
* @param command - The command string (e.g., 'activate-feature', 'run-simulation').
* @param payload - Optional data accompanying the command.
* @returns Optional response from the command execution.
*/
onCommand?(command: string, payload?: any): Promise<any>;
/**
* Called when the plugin is being shut down or unloaded. Used for cleanup.
*/
onShutdown?(): Promise<void>;
}
```
b.  Extend Plugin Manifest Schema:
* Update contracts/plugins/pluginManifest.schema.json to include:
* An optional runtime_interface field (e.g., "v1", "gameEngine" - linking to versions of PluginRuntimeInterface).
* An optional capabilities array (e.g., "canMutateThoughts", "usesLLM", "providesMultimodalInput").
* An optional activation_criteria object to support basic context-aware loading (e.g., {"device_type": "Mac Studio", "user_role": "developer"}), preparing for Config + Loader Spec.
* An optional translation_plugins field as discussed for VTC.
c.  Update PluginHost (core/services/pluginHost.ts):
* Modify the PluginHost to conceptually load and manage plugins based on the extended manifest schema. Its stubbed methods should acknowledge these new fields.
* Verification: pluginRuntimeInterface.ts exists. pluginManifest.schema.json is updated. PluginHost is conceptually ready for these new features.
12. Phase 1 Final Cleanup & Goal Articulation:
* Framework Outcome: Core framework with SQLite persistence and API access is stable and tested. VTC and CCE foundations are laid. Plugin architecture is scaffolded for dynamic runtime plugins.
* Demo Implementation Outcome: React app is a functional client to the backend.
* Detailed Actions (for AI Agent - Claude and/or Developer):
a.  Code Cleanup and Linting:
* Run linters across all modified/new directories. Fix issues. Remove dead code.
b.  Documentation Review:
* Review all Phase 0 & 1 docs for clarity, consistency, accuracy.
c.  State Snapshot:
* Export graph via API: state_snapshots/v1.0_phase1_complete.json.
d.  Update Phase 1 Summary in Development Plan (This Document):
* (Developer action) Replace this task with the "Phase 1 Outcome" statement below.
> Phase 1 Outcome (Replace Task 12d with this statement upon completion):
> LogoMesh has successfully transitioned to a client-server architecture with persistent data storage. A Node.js/Express.js backend API server, configurable via environment variables and runnable on Replit, now manages all data operations. This server utilizes an IdeaManager powered by an SQLiteStorageAdapter to interact with a normalized SQLite database (schema defined in schema.sql, initialized by initDb.ts). The React frontend has been fully refactored to consume this API for all thought, segment, and related data management, including JSON import/export handled by a core PortabilityService. The Cytoscape.js graph visualization correctly implements compound nodes with an fcose layout. An initial LLM execution layer (LLMTaskRunner, LLMExecutor interface with a mock/simple implementation, and llmAuditLogger) is integrated into the backend, accessible via an API endpoint. Crucially, foundational interfaces for the Vector Translation Core (VTC) have been established within contracts/embeddings/ and core/embeddings/, and an ephemeral embedding policy is implemented to prepare for secure, universal embedding translation in Phase 2. A conceptual placeholder for the Cognitive Context Engine (CCE) is in place, with the ThoughtExportProvider enhanced to support semantic compression for its future needs. Furthermore, a formal PluginRuntimeInterface has been scaffolded within core/plugins/, and the PluginManifest schema extended to support dynamic runtime plugins with context-aware loading and translation capabilities, preparing the system for advanced simulation, game engine, and multi-agent integrations. Node-RED has been set up with foundational API integrations for basic automation workflows, including a backend-triggered database backup mechanism. A script and process for migrating legacy localStorage data to SQLite are established. The backend API and core data services have improved unit and integration test coverage. The backend API and database are containerized using Docker for consistent local development. This architecture establishes LM-Core as a modular, AI-ready framework suitable for rapid development of future applications. Its separation of storage logic, execution layers, and automation workflows ensures high adaptability across domains and deployment targets. The system is now robustly prepared for the introduction of more advanced AI features, embedding infrastructure, and refined user interactions in Phase 2.
