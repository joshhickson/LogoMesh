### Story #3 — “Library-Latency Tango”

**Setup**
Liam turns his water-cooled Threadripper PC into a **LogoMesh “Home-Node”**:

* **Heavy modules on the PC**

  * `OllamaExecutor-GPU` (70 B local LLM)
  * `PatternMiner` (Python NLP plugin that clusters argumentative themes)
  * `VectorStore-PGVec` (PostgreSQL + pgvector)
  * `RollingSnapshotDaemon` (writes five-minute state deltas to ZFS)

* **Light modules on the iPad (library Wi-Fi)**

  * `ShellNode-Lite` canvas UI (React/TS)
  * `OfflineEventQueue` (captures actions when disconnected)

Both devices link through **EchoMesh**—LogoMesh’s peer tunnel that exposes the PC’s Plugin API over WireGuard.

---

#### Event chain

* **12 : 05** Liam arrives at the public library, connects his iPad to flaky guest Wi-Fi, and opens ShellNode-Lite. It handshake-pings Home-Node; latency is 140 ms but steady.
* **12 : 07** He drags three DOCX files into the canvas—old op-eds on free-speech jurisprudence. The uploads stream directly to the PC; `PatternMiner` begins chunking, vectorising, and clustering with GPU help.
* **12 : 10** The library router hiccups. ShellNode-Lite detects lost packets, switches to **OfflineEventQueue mode**, and shows a yellow “Sync paused” badge. Meanwhile, Home-Node keeps crunching.
* **12 : 12** `PatternMiner`’s NumPy dependency hits a rare BLAS segfault. Core’s watchdog:

  1. Flags the plugin with `STATUS=crashed`.
  2. Rolls back the last transaction batch in `VectorStore-PGVec` (atomic snapshot #42).
  3. Restarts only `PatternMiner` inside a fresh Python venv, leaving the LLM thread untouched.
  4. Logs the heap dump for post-mortem.
* **12 : 14** Wi-Fi returns. OfflineEventQueue pushes its delta—two note edits and a tag rename—to Home-Node. Core replays them against the *current* DB head; no conflicts, fast-forward succeeds.
* **12 : 16** `PatternMiner` finishes on the second run and emits five emergent theme clusters with confidence scores. ShellNode-Lite’s canvas refreshes; Liam taps one cluster and gets an auto-generated thesis outline:

> *“While tech platforms claim neutrality, their algorithmic opacity erodes the marketplace of ideas.”*

He copies it straight into his draft.

* **12 : 25** A toast appears: “`PatternMiner` crash recovered (segfault); report saved.” Liam keeps writing, oblivious to the earlier failure.

---

#### Why this matters for Phase 2

To make Liam’s seamless “compute-everywhere” flow possible, Phase 2 must lock in:

| Capability                                | Concrete requirement                                                                                        |
| ----------------------------------------- | ----------------------------------------------------------------------------------------------------------- |
| **Distributed plugin manifest**           | Any device can declare which plugins run locally vs. remotely; EchoMesh must route API calls transparently. |
| **Offline-first event journaling**        | Front-end queues MUST survive network drops and be replayable idempotently.                                 |
| **Per-plugin watchdog + scoped rollback** | A crashing Python module can’t taint the vector index or kill the GPU LLM process.                          |
| **Atomic multi-stage pipelines**          | Upload → vectorize → cluster must commit as one logical unit so rollbacks are clean.                        |
| **Snapshot & resume**                     | RollingSnapshotDaemon lets Liam power-cycle the PC without data loss; clients re-hydrate automatically.     |

If Phase 2 nails these, LogoMesh feels like one coherent brain no matter where the heavy silicon lives—or how terrible the library Wi-Fi gets.
