Here is the rewritten Phase 1 Development Plan, version 3.0, incorporating all the architectural decisions for the Cognitive Context Engine (CCE) and Vector Translation Core (VTC), and aligning with your improved workflow for AI agent development.
This updated plan includes provisions for the plugin contract layer, runtime logic/command bus, and input/output interfaces, specifically focusing on stubbing out the necessary interfaces and modifying Phase 1 tasks to ensure future compatibility, as discussed.
PHASE 1: Backend Implementation, Data Persistence, and Core AI Foundation Scaffolding (v3.0)
Estimated Duration: 3-4 Weeks
Prerequisite: Successful completion of all Phase 0: Framework-First Architecture Setup & Core Logic Decoupling tasks. This implies the following project state:
 * A React application in src/ that has been decoupled from direct data management.
 * An in-memory IdeaManager managing thought data for the session after an initial load from localStorage.
 * TypeScript data contracts (DTOs) for Thought, Segment, Tag, LLMExecutor, etc., defined in contracts/.
 * Core utilities for ID generation (core/utils/idUtils.ts) and logging (core/utils/logger.ts, core/logger/llmAuditLogger.ts).
 * Basic unit test stubs for IdeaManager in core/.
 * Path aliases (@core, @contracts) configured in tsconfig.json (or jsconfig.json) with baseUrl: "." and paths for src, core, and contracts.
 * Placeholder documentation for DevOps, UX, and data migration.
Goal:
This phase transitions LogoMesh from an application reliant on in-memory data (post-initial load) to a robust, local-first application with persistent data storage using SQLite. It involves building a lightweight backend API server (Node.js/Express.js), integrating SQLite into the core data management layer (IdeaManager) via a StorageAdapter pattern, and connecting the React frontend to this new backend. Crucially, this phase also lays fundamental architectural groundwork for the Vector Translation Core (VTC) and the Cognitive Context Engine (CCE), ensuring future AI capabilities can be seamlessly integrated. This includes refining the graph visualization, laying the groundwork for local automation with Node-RED, and implementing the initial (mocked/stubbed) LLM execution layer. All development must adhere to environment-aware configurations for flexible deployment (local development and Replit).
Key Outcomes for Phase 1:
 * A functional backend API server (Node.js/Express.js) serving data from an SQLite database, configurable via environment variables.
 * The IdeaManager refactored to use a persistent SQLite data store through a StorageAdapter pattern.
 * The React application (src/) fully communicates with the backend API for all core data operations.
 * An initial, simple implementation of the LLMExecutor interface (e.g., for Ollama as a mock) and LLMTaskRunner integrated into the backend, designed to support future VTC and optional external LLMs via API keys.
 * Node-RED instance set up with foundational API integrations to the backend for basic automation workflows.
 * Cytoscape.js graph visualization in the React app refined for compound nodes and fcose layout.
 * JSON import/export functionality available via the backend API.
 * The backend API and SQLite database containerized using Docker for consistent local development.
 * A defined process and script for migrating initial data from localStorage to the new SQLite database.
 * Sample Replit configuration files (.replit, replit.nix) for demo deployment.
 * Foundational interfaces and architectural provisions for the Vector Translation Core (VTC) are stubbed within contracts/embeddings/ and core/embeddings/, ensuring all embedding interactions are abstracted and ephemeral.
 * Foundational interfaces and conceptual plans for the Cognitive Context Engine (CCE) are planned within core/services/ (or core/context/), with the ThoughtExportProvider being enhanced to support semantic compression for its future needs.
Tier #1: Local-First Full Immersion
Tasks:
1. Project & Environment Setup for Phase 1 Backend Development:
* Framework Outcome: Core services and the new server can be configured via environment variables. Project structure is prepared for backend development and Replit deployment.
* Detailed Actions (for AI Agent):
a.  Establish .env Configuration:
* Create an .env.example file in the project root directory.
* Populate it with placeholder environment variables for:
* PORT (e.g., 3001)
* API_BASE_PATH (e.g., /api/v1)
* DB_PATH (e.g., ./data/logomesh.sqlite3 - this path will be relative to where the server runs, likely server/data/logomesh.sqlite3 or a Replit persistent path).
* PLUGIN_DIR (e.g., ./plugins - relative to server/core).
* LOG_LEVEL (e.g., info).
* DEFAULT_LLM_EXECUTOR (e.g., MockLLMExecutor).
* ULS_DIMENSION (e.g., 768) - New for VTC scaffolding.
* REACT_APP_API_URL (e.g., http://localhost:3001/api/v1) - For frontend configuration.
* Add .env to the .gitignore file.
* (Note for AI Agent): Subsequent tasks will require reading these variables using process.env.VARIABLE_NAME || 'defaultValue'.
b.  Create Replit Configuration Files (for replit-demo branch):
* Generate a sample .replit file in the project root.
* The run command should correctly start the backend API server (e.g., cd server && npm run start or pnpm --filter ./server start).
* It should respect environment variables provided by Replit (like $PORT).
* Generate a sample replit.nix file in the project root.
* Include pkgs.nodejs (e.g., v18 or v20) and pkgs.sqlite (system library for the sqlite3 Node.js module).
* Define any necessary environment variables if Replit doesn't set them automatically (e.g., DB_PATH pointing to Replit's persistent storage like /mnt/data/logomesh.sqlite3).
* Verification: Project can be configured to run on Replit.
2. Backend API Server & SQLite Database Foundation:
* Framework Outcome: A runnable Node.js/Express.js backend server and an initialized SQLite database with the correct schema.
* Detailed Actions (for AI Agent):
a.  Set Up Backend Server Project (server/ directory):
* Create a new top-level directory named server/.
* Initialize a Node.js project within server/ (npm init -y or equivalent).
* Install dependencies: express, cors, sqlite3.
* Set up for TypeScript: install typescript, @types/express, @types/cors, @types/node, ts-node, nodemon as dev dependencies. Create server/tsconfig.json (module: commonjs, target: es2020, outDir: ./dist, rootDir: ./src, esModuleInterop: true, resolveJsonModule: true). Create server/src/ for source files. Add build/start/dev scripts to server/package.json.
* Create server/src/index.ts as the main server entry point.
* Implement Express app setup: use cors(), express.json().
* Add a GET /api/v1/health route (use process.env.API_BASE_PATH) returning { status: "healthy", timestamp: new Date().toISOString() }.
* Start server on process.env.PORT || 3001.
* Implement Bootstrap Logging: At startup, log (using @core/utils/logger.ts via relative path or updated alias) the perceived environment, port, DB_PATH (from process.env), and PLUGIN_DIR.
* Verification: Express server starts, health check works, bootstrap logs appear.
b.  Define and Initialize SQLite Database Schema:
* (Prerequisite Check): Ensure the "Phase 1 SQLite Schema" section in docs/Merged Milestone-Based Development Plan v2.0.md is complete and accurate, detailing all tables, columns, types, keys, and constraints for thoughts, segments, tags, thought_tags, segment_tags, segment_fields, segment_neighbors, segment_related_context, segment_llm_history.
* In core/db/schema.sql (created in Phase 0), populate with CREATE TABLE statements from the verified plan.
* In core/db/initDb.ts (created in Phase 0), implement initializeDatabase():
* Use sqlite3. Connect to process.env.DB_PATH (defaulting to server/data/logomesh.sqlite3 if run from server dir, or core/db/logomesh.sqlite3 if run from core dir â€“ path needs to be robust). Create the data directory if it doesn't exist.
* Read core/db/schema.sql. Execute CREATE TABLE IF NOT EXISTS ... for all tables.
* Use logger from core/utils/logger.ts.
* Modify server/src/index.ts startup sequence to call await initializeDatabase() before starting the Express listener, ensuring the DB is ready. Handle potential errors during DB initialization.
* Verification: Server startup initializes the DB. logomesh.sqlite3 is created at the configured DB_PATH with the correct schema.
c.  Integrate LLM Execution Layer Stubs:
* Create core/llm/OllamaExecutor.ts implementing LLMExecutor from contracts/llmExecutor.ts. executePrompt returns a mocked response (e.g., Promise.resolve(\Mocked response for: ${prompt}`)). supportsStreamingisfalse. * Create core/llm/LLMTaskRunner.tsclass withconstructor(private executor: LLMExecutor)andasync run(prompt: string, metadata?: Record<string, any>): Promise<string>method that callsthis.executor.executePromptand logs vialogLLMInteractionfromcore/logger/llmAuditLogger.ts. Include the runPromptWithStreaming?stub. * Createcore/llm/utils/mermaidAuditor.tswith stubisValidMermaidfunction. * Createserver/src/routes/llmRoutes.ts: POST /api/v1/llm/promptendpoint usingLLMTaskRunnerwith an instance ofMockLLMExecutor(fromcore/llm/MockLLMExecutor.tscreated in Phase 0) or the newOllamaExecutorstub. Mount this router inserver/src/index.ts. * **Crucial VTC Preparation:** Ensure LLMExecutorimplementations (includingMockLLMExecutorandOllamaExecutor.tsstub) **do not hardcode assumptions about embedding formats or types**. They should be designed to receive context/prompts that *could* originate from a VTC-translated source in future phases. * *Verification:*POSTto/api/v1/llm/promptreturns mock response and logs viallmAuditLogger`.
d.  Define VTC & Embedding Interfaces (Crucial for Phase 2 readiness):
* Purpose: To establish the foundational TypeScript interfaces for the Vector Translation Core (VTC), ensuring that all embedding interactions within LogoMesh are abstracted and that the system is ready for multi-model and multi-modal embedding translation in Phase 